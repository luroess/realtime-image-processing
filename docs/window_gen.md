# Window Generator (Line Buffers + Sliding $K \times K$ Window)

---

**NOTE:** This file was generated by GPT5.2 via ChatGPT.

---

The window generator is the **data-prep block** that turns a 1D pixel stream into a **$K \times K$ neighborhood** each cycle. It **does not** compute the convolution; it only outputs the window for downstream filters (blur/Sobel/morphology/FAST).

## What it produces (example $K=3$)

For output pixel at $(x,y)$, a $3 \times 3$ window is:

$$
W(x,y)=
\begin{bmatrix}
p(x-1,y-1) & p(x,y-1) & p(x+1,y-1) \\
p(x-1,y)   & p(x,y)   & p(x+1,y)   \\
p(x-1,y+1) & p(x,y+1) & p(x+1,y+1)
\end{bmatrix}
$$

Downstream then computes e.g. a convolution:
$$
y(x,y) = \sum_{i=0}^{K-1}\sum_{j=0}^{K-1} k_{ij}\, W_{ij}(x,y)
$$

## Design pattern

For a $K \times K$ window on a row-major stream:

- **Line buffers needed:** $N_{lb} = K - 1$ (store previous rows)
- **Horizontal taps per row-stream:** $K$ (shift registers)
- **Throughput:** after warm-up, $1\ \text{window}/\text{cycle}$ (i.e., 1 px/clk) is achievable.

This is the canonical FPGA pattern for streaming 2D filters.

Reference (Window2D / line+window buffers):
- https://docs.amd.com/r/en-US/Vitis-Tutorials-Vitis-Hardware-Acceleration/Window2D-Line-and-Window-Buffers

## Recommended internal stream interface

We use a simple VHDL-friendly pixel stream (independent of external IP wiring):

Inputs:
- `i_pix_valid`, `i_pix_data`
- `i_pix_sof` (start-of-frame), `i_pix_eol` (end-of-line)

Outputs:
- `o_win_valid`
- `o_win_px[...]` (flattened $K \times K$ window bus or record)
- delayed `o_pix_sof`, `o_pix_eol` aligned to the window center pixel

If upstream is AXI4-Stream Video:
- `tvalid -> i_pix_valid`, `tdata -> i_pix_data`
- `tuser -> i_pix_sof` (`SOF`), `tlast -> i_pix_eol` (`EOL`)

AXI4-Stream Video semantics (`SOF`/`EOL`, packing):
- UG934: https://docs.amd.com/r/en-US/ug934_axi_videoIP

## Implementation sketch ($K=3$)

Let frame width be $W$ pixels. Maintain two BRAM line buffers:

- `LB1`: row $(y-1)$, depth $W$
- `LB2`: row $(y-2)$, depth $W$

Per valid pixel at column `col`:

1) write current pixel into `LB1[col]`
2) read `LB1[col]` -> pixel from `row-1`
3) write that value into `LB2[col]`
4) read `LB2[col]` -> pixel from `row-2`

Now you have three aligned vertical pixels per cycle: `(row2,row1,row0)`.

For each row stream, keep a `K`-tap shift register to get columns $(x, x-1, ..., x-(K-1))$.

## Warm-up / border policy

If we **drop borders** (fastest, simplest), the window is valid only when:

$$
\texttt{o\_win\_valid} = \texttt{i\_pix\_valid} \wedge (\texttt{row} \ge K-1) \wedge (\texttt{col} \ge K-1)
$$

Alternative policies (must match the golden model):
- zero padding
- replicate padding

## Latency + alignment

Line buffers (BRAM) typically add 1-cycle read latency, plus any explicit pipelining. All framing signals (`SOF`/`EOL`) must be delayed by the same pipeline latency so that metadata stays aligned with the window center pixel.

## Minimal cocotb unit test

Use tiny frames (e.g., 16x12) for speed.

1) Generate a ramp image $p(x,y)=x+16y$
2) Drive the stream and, for each cycle with `o_win_valid=1`, assert the $K \times K$ window matches the reference neighborhood.
3) Assert:
- `SOF` occurs once per frame at first pixel
- `EOL` occurs once per line at last pixel

cocotb docs:
- https://docs.cocotb.org/en/stable/

## Extension notes (FAST / larger windows)

FAST often needs a larger neighborhood (e.g., $7 \times 7$) to cover the 16-pixel circle around the center. Options:
- build a dedicated $7 \times 7$ window generator, or
- parameterize `K` (more reusable, more work).
